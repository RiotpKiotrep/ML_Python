# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s-QzWmT_0Weh-2EA6cIowRutjhsq0Bec

# Import necessary libraries
"""

#Importing necessary libraries
import pandas as pd
import numpy as np
import math
import operator

pd.set_option('display.max_columns', None)

from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""# Import data - UNSW-NB15 Dataset

"""

#Import data
train_url = "https://drive.google.com/uc?id=1Jm25hKfLh61phgdKA9Aj2QQVnUug_0uz&export=download"
test_url = "https://drive.google.com/uc?id=1tWypzJIfEj07qwAaT6y8raMCI0od3S8T&export=download"

print("Importing train data...")
training_df = pd.read_csv(train_url, sep=',', on_bad_lines='warn')
print("Importing test data...")
testing_df = pd.read_csv(test_url, sep=',', on_bad_lines='warn')

# remove columns that don't match
cols_to_remove = ['id', 'service', 'state', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',
       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',
       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',
       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',
       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',
       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',
       'ct_srv_dst', 'is_sm_ips_ports']

training_df = training_df.drop(cols_to_remove, axis=1)
testing_df = testing_df.drop(cols_to_remove, axis=1)

combined_df = pd.concat([training_df, testing_df], axis=0)

#combined_df.head()

cols = training_df.columns
training_df.rename(columns={cols[i]: i for i in range(cols.shape[0])}, inplace=True)
testing_df.rename(columns={cols[i]: i for i in range(cols.shape[0])}, inplace=True)
combined_df.rename(columns={cols[i]: i for i in range(cols.shape[0])}, inplace=True)
# replace protocols with numbers
proto_values = np.concatenate((training_df[1].unique(), testing_df[1].unique()))
proto_values = np.unique(proto_values)
print(proto_values)
training_df[1].replace(proto_values, [i for i in range(len(proto_values))], inplace=True)
testing_df[1].replace(proto_values, [i for i in range(len(proto_values))], inplace=True)
combined_df[1].replace(proto_values, [i for i in range(len(proto_values))], inplace=True)

# to float128
cols_to_cast = [i for i in range(cols.shape[0]-2)]
training_df[cols_to_cast] = training_df[cols_to_cast].astype(np.float64)
testing_df[cols_to_cast] = testing_df[cols_to_cast].astype(np.float64)
combined_df[cols_to_cast] = combined_df[cols_to_cast].astype(np.float64)

"""# Import data - FW Log"""

#log_url = "https://drive.google.com/uc?id=15XAPp6t8RuQLplMKRZheSNeWytiEy-1v&export=download"
log_url = "https://drive.google.com/uc?id=1LapUS2IGCG7m4JD7hMfb-wMGWyIy2Tva&export=downloa"
print("Importing log data...")
log_df = pd.read_csv(log_url, sep=',', on_bad_lines='warn')

#log_df['Receive Time'] = pd.to_datetime(log_df['Receive Time'])
#mask = log_df['Receive Time'].dt.date == pd.to_datetime('2024-08-29').date()
mask = log_df['Source address'] == '192.168.0.10'
log_df.loc[mask, 'Action'] = 'block'

cols_to_keep = ['Elapsed Time (sec)', 'IP Protocol', 'Packets Sent', 'Packets Received', 'Bytes Sent', 'Bytes Received', 'Threat/Content Type', 'Action']
log_df = log_df[cols_to_keep]

cols = log_df.columns
log_df.rename(columns={cols[i]: i for i in range(cols.shape[0])}, inplace=True)

action_values = ['block', 'allow']
log_df[7].replace(action_values, [i for i in range(len(action_values))], inplace=True)

# replace protocols with numbers
log_df[1].replace(proto_values, [i for i in range(len(proto_values))], inplace=True)
# to float128
log_df[cols_to_cast] = log_df[cols_to_cast].astype(np.float64)

"""# KNN - set params"""

# scaling
scaler = RobustScaler()
scaler.fit(combined_df.iloc[:, :-2])
knn = KNeighborsClassifier(n_neighbors=8, weights='uniform', metric='manhattan')

"""# KNN - algorithm"""

# TRAIN: INTERNET_TRAINING, TEST: LOG
X_train = training_df.iloc[:, :-2].values
y_train = training_df.iloc[:, -1].values
X_train = scaler.transform(X_train)

print(f"Test file: log_current.csv")

X_test = log_df.iloc[:, :-2].values
y_test = log_df.iloc[:, -1].values
X_test = scaler.transform(X_test)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion matrix:\n", conf_matrix)

class_report = classification_report(y_test, y_pred)
print("Classification report:\n", class_report)
print("\n")